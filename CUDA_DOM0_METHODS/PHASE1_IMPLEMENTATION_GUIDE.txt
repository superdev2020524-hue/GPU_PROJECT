================================================================================
PHASE 1 IMPLEMENTATION GUIDE - DETAILED BREAKDOWN
================================================================================
Project: H100 GPU Mediation Layer for XCP-ng
Approach: Option A - Minimal PCI Stub with Mediation Daemon
Date: December 14, 2025

================================================================================
TABLE OF CONTENTS
================================================================================
1. Overview & Terminology
2. Architecture Diagram
3. Component 1: PCI Stub Device (Host Side)
4. Component 2: VM Guest Driver
5. Component 3: Mediation Daemon (Host Side)
6. Step-by-Step Implementation Plan
7. Time Estimates
8. Testing Strategy
9. Troubleshooting Guide

================================================================================
SECTION 1: OVERVIEW & TERMINOLOGY
================================================================================

What We're Building in Phase 1:
-------------------------------
A simple system where a VM can send GPU commands to the host, and the host
executes those commands on the real H100 GPU.

Think of it like a restaurant:
- VM = Customer (orders food)
- PCI Stub = Waiter (takes orders)
- Mediation Daemon = Kitchen (cooks food using real equipment)
- H100 GPU = Stove/oven (the actual hardware)

Key Terms Explained:
-------------------

1. PCI STUB DEVICE
   What it is: A fake/dummy PCI device that appears in the VM
   Purpose: Gives the VM something to talk to (like a phone number to call)
   NOT: A real GPU - just a communication endpoint
   Location: Runs on the HOST, visible to VM
   
2. MEDIATION DAEMON
   What it is: A program running on the host that does the real GPU work
   Purpose: Receives commands from VMs and executes CUDA on the real H100
   Think of it as: A translator and executor
   Location: Runs on HOST in user-space or as a service
   
3. GUEST DRIVER
   What it is: A small kernel module inside the VM
   Purpose: Lets VM programs talk to the PCI stub device
   Creates: /dev/vgpu_stub device file that programs can open/write to
   Location: Runs INSIDE the VM
   
4. SHARED MEMORY / RING BUFFER
   What it is: A memory region both VM and host can access
   Purpose: Fast communication channel between VM and host
   Think of it as: A shared mailbox
   
5. XENSTORE
   What it is: Xen's built-in key-value store for VM-host communication
   Purpose: Exchange configuration and simple messages
   Alternative to: Shared memory (simpler but slower)

================================================================================
SECTION 2: ARCHITECTURE DIAGRAM
================================================================================

Physical Layout:
===============

┌───────────────────────────────────────────────────────────────┐
│                         HOST MACHINE (XCP-ng)                 │
│                                                               │
│  ┌─────────────────────────────────────────────────────────┐  │
│  │ VM #1                                                   │  │
│  │                                                         │  │
│  │  ┌─────────────────────┐                                │  │
│  │  │ Test Application    │  (Simple C program)            │  │
│  │  │ ./gpu_test          │                                │  │
│  │  └──────────┬──────────┘                                │  │
│  │             │ open("/dev/vgpu_stub")                    │  │
│  │             │ write("RUN_VECTOR_ADD")                   │  │
│  │             ↓                                           │  │
│  │  ┌─────────────────────┐                                │  │
│  │  │ Guest Driver        │  (Kernel module in VM)         │  │
│  │  │ vgpu_stub.ko        │                                │  │
│  │  └──────────┬──────────┘                                │  │
│  │             │                                           │  │
│  │             │ Writes to PCI BAR                         │  │
│  └─────────────┼───────────────────────────────────────────┘  │
│                │                                              │
│                ↓ (Hypervisor intercepts)                      │
│                │                                              │
│  ┌─────────────┼───────────────────────────────────────────┐  │
│  │             ↓                                           │  │
│  │  ┌──────────────────────┐    ┌─────────────────────┐    │  │
│  │  │ PCI Stub Device      │←──→│ Shared Memory       │    │  │
│  │  │ (Xen device backend) │    │ Ring Buffer         │    │  │
│  │  └──────────┬───────────┘    └──────────┬──────────┘    │  │
│  │             │                           │               │  │
│  │             └──────────┬────────────────┘               │  │
│  │                        │                                │  │
│  │                        ↓                                │  │
│  │             ┌────────────────────────┐                  │  │
│  │             │ MEDIATION DAEMON       │                  │  │
│  │             │ (gpu_mediator)         │                  │  │
│  │             │                        │                  │  │
│  │             │ - Receives commands    │                  │  │
│  │             │ - Schedules work       │                  │  │
│  │             │ - Calls CUDA           │                  │  │
│  │             └────────────┬───────────┘                  │  │
│  │                          │                              │  │
│  │                          │ CUDA API calls               │  │
│  │                          ↓                              │  │
│  │             ┌────────────────────────┐                  │  │
│  │             │ NVIDIA Driver (Host)   │                  │  │
│  │             │ /dev/nvidia0           │                  │  │
│  │             └────────────┬───────────┘                  │  │
│  │                          │                              │  │
│  │                          ↓                              │  │
│  │             ┌────────────────────────┐                  │  │
│  │             │  REAL H100 GPU         │                  │  │
│  │             │  (Physical Hardware)   │                  │  │
│  │             └────────────────────────┘                  │  │
│  │                                                         │  │
│  └─────────────────────────────────────────────────────────┘  │
└───────────────────────────────────────────────────────────────┘

Data Flow Example:
==================

1. VM test app writes: "RUN_VECTOR_ADD"
2. Guest driver receives write, puts command in shared memory
3. PCI stub device signals mediation daemon: "New command available"
4. Mediation daemon reads command from shared memory
5. Mediation daemon executes CUDA vector_add kernel on real H100
6. Result returned: "SUCCESS: 1024 elements added correctly"
7. Mediation daemon writes result to shared memory
8. Guest driver reads result and returns to test app
9. Test app prints: "GPU test passed!"

================================================================================
SECTION 3: COMPONENT 1 - PCI STUB DEVICE (Host Side)
================================================================================

What Is It?
-----------
A Xen device backend that creates a fake PCI device visible inside the VM.
This is NOT a full GPU emulation - just a simple device with:
- A vendor ID (NOT NVIDIA's 0x10de)
- A device ID (custom)
- One or two Base Address Registers (BARs) for memory-mapped I/O
- Interrupt capability (MSI-X)

What Does It Do?
----------------
1. Appears in VM's lspci output as a simple device
2. Provides memory regions (BARs) that the guest driver can write to
3. Forwards those writes to the mediation daemon
4. Signals interrupts back to the VM when work is done

Location in Xen:
----------------
Typically implemented as a Xen device model extension:
- Path: /usr/lib/xen/bin/ or integrated into qemu-dm (device model)
- Language: Usually C
- Interfaces with: libxl (Xen toolstack library)

Key Files to Create:
--------------------

1. vgpu_stub_device.c
   - Implements PCI device configuration space
   - Handles BAR read/write operations
   - Creates shared memory ring
   - Signals mediation daemon

2. vgpu_stub_backend.c
   - Xen backend driver
   - Manages VM connections
   - Sets up XenStore entries
   - Handles VM lifecycle (start/stop)

3. vgpu_stub.cfg (Xen device configuration)
   - Defines device parameters
   - PCI vendor/device IDs
   - Memory region sizes

What Needs to Be Done:
----------------------

Step 3.1: Define PCI Device Configuration
   Task: Choose vendor/device IDs and device class
   Output: Device will appear in lspci
   Example:
     Vendor ID: 0x1AF4 (Red Hat/virtio - often used for virtual devices)
     Device ID: 0x1111 (custom)
     Class: 0x0C (Generic system peripheral) or 0x12 (Processing accelerator)

Step 3.2: Implement PCI Configuration Space
   Task: Write code to respond to PCI config space reads
   File: vgpu_stub_device.c
   Functions:
     - vgpu_stub_pci_config_read()
     - vgpu_stub_pci_config_write()

Step 3.3: Create BAR (Base Address Register)
   Task: Allocate memory region for VM-to-host communication
   Size: Start with 4KB (one page)
   Layout:
     Offset 0x000: Command register (what operation to do)
     Offset 0x004: Status register (result code)
     Offset 0x008: Data offset (pointer to payload)
     Offset 0x100: Data region (command parameters)

Step 3.4: Set Up Shared Memory Ring
   Task: Create ring buffer for command/response
   Use: Xen grant tables for secure shared memory
   Library: libxenctrl (xenctrl.h)
   Functions:
     - xc_gnttab_map_grant_ref() - map VM memory to host
     - xc_evtchn_bind_interdomain() - set up event channel

Step 3.5: Implement Backend Operations
   File: vgpu_stub_backend.c
   Operations:
     - probe() - called when VM requests device
     - connect() - establish communication with VM
     - disconnect() - clean up when VM stops
     - handle_request() - process commands from VM

Step 3.6: XenStore Integration
   Task: Register device in XenStore
   Path: /local/domain/<domid>/device/vgpu/0
   Entries:
     - backend = /local/domain/0/backend/vgpu/<domid>/0
     - state = connected
     - ring-ref = <grant ref for shared memory>
     - event-channel = <event channel number>

Estimated Time for PCI Stub Device:
-----------------------------------
Senior Developer: 5-7 days
Breakdown:
  - Day 1-2: Set up build environment, study Xen device model
  - Day 3-4: Implement PCI config space and BAR handling
  - Day 5-6: Shared memory and XenStore integration
  - Day 7: Testing and debugging with simple VM

================================================================================
SECTION 4: COMPONENT 2 - VM GUEST DRIVER
================================================================================

What Is It?
-----------
A Linux kernel module that runs INSIDE the VM. It detects the PCI stub device
and provides a character device (/dev/vgpu_stub) that user programs can use.

What Does It Do?
----------------
1. Detects the PCI stub device during boot
2. Maps the device's BAR into VM kernel memory
3. Creates /dev/vgpu_stub device file
4. Handles open/read/write/ioctl system calls
5. Writes commands to shared memory
6. Waits for and receives responses from host

Location:
---------
Inside the VM's kernel
Loaded with: insmod vgpu_guest.ko
Appears in: lsmod, /proc/devices

Key Files to Create:
--------------------

1. vgpu_guest.c
   Main driver file with:
   - PCI driver structure
   - Character device operations
   - Interrupt handler

2. vgpu_guest.h
   Header with data structures and command definitions

3. Makefile
   Kernel module build configuration

4. vgpu_guest.conf (optional)
   Module parameters and configuration

What Needs to Be Done:
----------------------

Step 4.1: PCI Driver Registration
   Task: Register driver with kernel PCI subsystem
   Code structure:
   
   static struct pci_device_id vgpu_ids[] = {
       { PCI_DEVICE(0x1AF4, 0x1111) },  // Match our vendor/device ID
       { 0, }
   };
   
   static struct pci_driver vgpu_driver = {
       .name = "vgpu_stub",
       .id_table = vgpu_ids,
       .probe = vgpu_probe,
       .remove = vgpu_remove,
   };

Step 4.2: PCI Probe Function
   Task: Called when kernel finds matching PCI device
   Operations:
   - Enable PCI device
   - Request memory regions (BARs)
   - Map BAR to kernel virtual memory
   - Set up DMA if needed
   - Register interrupt handler
   
   Function: vgpu_probe(struct pci_dev *pdev, ...)

Step 4.3: Character Device Creation
   Task: Create /dev/vgpu_stub that apps can open
   Steps:
   - Allocate device number (major/minor)
   - Initialize cdev structure
   - Create device class
   - Create device node
   
   Functions:
   - alloc_chrdev_region()
   - cdev_init() and cdev_add()
   - device_create()

Step 4.4: Implement File Operations
   Task: Handle open/read/write/close from user programs
   
   Operations needed:
   
   a) vgpu_open()
      - Allow process to open /dev/vgpu_stub
      - Allocate per-process state
   
   b) vgpu_write()
      - Receive command from user program
      - Validate command
      - Write to shared memory ring
      - Signal host via event channel
      - Wait for response
      - Return result to user
   
   c) vgpu_read()
      - Return status/results to user
   
   d) vgpu_ioctl()
      - Handle control operations
      - Query device status
      - Configure parameters

Step 4.5: Shared Memory Access
   Task: Read/write to ring buffer shared with host
   
   Ring buffer structure:
   
   struct vgpu_ring {
       uint32_t req_prod;  // Request producer index (VM writes)
       uint32_t req_cons;  // Request consumer index (host reads)
       uint32_t rsp_prod;  // Response producer index (host writes)
       uint32_t rsp_cons;  // Response consumer index (VM reads)
       struct vgpu_request requests[RING_SIZE];
       struct vgpu_response responses[RING_SIZE];
   };
   
   Operations:
   - Check if ring has space before writing
   - Update producer index after writing
   - Check consumer index to see if host processed request
   - Handle wrap-around (circular buffer)

Step 4.6: Event Channel Handling
   Task: Notify host and receive notifications
   
   Send notification:
   - After writing command to ring, call notify_remote_via_evtchn()
   
   Receive notification:
   - Register interrupt handler: bind_evtchn_to_irqhandler()
   - Handler wakes up waiting processes

Step 4.7: Command Protocol
   Task: Define commands the VM can send
   
   Phase 1 Commands:
   
   #define VGPU_CMD_NOP          0  // No operation (ping test)
   #define VGPU_CMD_VECTOR_ADD   1  // Run vector addition test
   #define VGPU_CMD_QUERY_STATUS 2  // Query GPU status
   
   struct vgpu_request {
       uint16_t cmd;           // Command type
       uint16_t flags;         // Option flags
       uint32_t id;            // Request ID
       uint32_t data_len;      // Length of data
       uint64_t data_ptr;      // Pointer to data (if needed)
   };
   
   struct vgpu_response {
       uint32_t id;            // Matches request ID
       int32_t  status;        // 0 = success, negative = error
       uint32_t data_len;      // Length of response data
       char     data[256];     // Response data
   };

Estimated Time for Guest Driver:
---------------------------------
Senior Developer: 4-6 days
Breakdown:
  - Day 1-2: PCI driver skeleton and device detection
  - Day 3: Character device and file operations
  - Day 4-5: Shared memory ring and event channels
  - Day 6: Testing and debugging

================================================================================
SECTION 5: COMPONENT 3 - MEDIATION DAEMON (Host Side)
================================================================================

What Is It?
-----------
A user-space program (or system service) running on the host that:
1. Monitors shared memory rings for commands from VMs
2. Executes actual CUDA operations on the real H100
3. Returns results back to VMs

Think of it as: The "brain" that does the real GPU work

What Does It Do?
----------------
1. Starts at boot as a system service
2. Connects to PCI stub device backend
3. Polls/monitors event channels from all VMs
4. Reads commands from shared memory
5. Validates and queues commands
6. Executes CUDA kernels on H100
7. Writes results back to VM shared memory
8. Signals VM that result is ready

Location:
---------
Host user-space: /usr/local/bin/gpu_mediator
Config: /etc/gpu_mediator/config.conf
Logs: /var/log/gpu_mediator.log

Key Files to Create:
--------------------

1. mediator_main.c
   - Main program loop
   - Command line parsing
   - Daemon initialization

2. mediator_vm.c
   - Per-VM state management
   - Shared memory mapping
   - Event channel handling

3. mediator_scheduler.c
   - Simple round-robin scheduler for Phase 1
   - Queue management

4. mediator_cuda.c
   - CUDA initialization
   - Test kernel execution
   - Error handling

5. mediator_protocol.c
   - Command parsing
   - Response formatting

6. mediator.h
   - Common data structures
   - Function prototypes

What Needs to Be Done:
----------------------

Step 5.1: Program Initialization
   Task: Set up daemon process
   
   Operations:
   - Parse command line arguments
   - Load configuration file
   - Initialize CUDA runtime
   - Detect H100 GPU
   - Set up signal handlers (SIGTERM, SIGHUP)
   - Fork to background (daemon mode)
   - Create PID file
   
   Function: main(), daemon_init()

Step 5.2: CUDA Initialization
   Task: Initialize CUDA and load test kernels
   
   Operations:
   - cudaSetDevice(0) - select H100
   - Query GPU properties
   - Load and compile test kernels
   - Allocate device memory pool
   - Create CUDA streams for concurrency
   
   File: mediator_cuda.c
   
   Example:
   
   int cuda_init() {
       int device_count;
       cudaGetDeviceCount(&device_count);
       if (device_count == 0) {
           return -1;  // No GPU
       }
       
       cudaSetDevice(0);  // Use first GPU
       
       // Query properties
       cudaDeviceProp prop;
       cudaGetDeviceProperties(&prop, 0);
       printf("GPU: %s\n", prop.name);  // Should show H100
       
       // Load test kernels
       load_vector_add_kernel();
       
       return 0;
   }

Step 5.3: VM Connection Management
   Task: Detect and connect to VMs that need GPU access
   
   How it works:
   - Watch XenStore for new VM device connections
   - For each VM, get:
     * Domain ID (VM identifier)
     * Grant reference (for shared memory)
     * Event channel number
   - Map VM's shared memory into host address space
   - Register event channel handler
   
   File: mediator_vm.c
   
   Structure:
   
   struct vm_context {
       uint32_t domid;              // VM domain ID
       void *ring;                  // Mapped ring buffer
       int evtchn_fd;               // Event channel file descriptor
       pthread_t thread;            // Worker thread for this VM
       struct vgpu_ring *shared;    // Pointer to shared ring
       int active;                  // Is VM still active?
   };
   
   Function: vm_connect(uint32_t domid)

Step 5.4: Event Loop / Main Loop
   Task: Monitor all VMs for new commands
   
   Approach: Use select() or epoll() to wait on multiple event channels
   
   Pseudocode:
   
   while (daemon_running) {
       // Wait for events from any VM
       fd_set readfds;
       FD_ZERO(&readfds);
       
       for (each VM) {
           FD_SET(vm->evtchn_fd, &readfds);
       }
       
       select(max_fd + 1, &readfds, NULL, NULL, &timeout);
       
       for (each VM) {
           if (FD_ISSET(vm->evtchn_fd, &readfds)) {
               // This VM has a new command
               process_vm_commands(vm);
           }
       }
   }

Step 5.5: Command Processing
   Task: Read and parse commands from VM
   
   Function: process_vm_commands(struct vm_context *vm)
   
   Steps:
   1. Read ring buffer
   2. Check req_prod vs req_cons (new requests?)
   3. For each new request:
      a. Parse command type
      b. Validate parameters
      c. Add to scheduler queue
      d. Update req_cons
   
   Example:
   
   void process_vm_commands(struct vm_context *vm) {
       struct vgpu_ring *ring = vm->shared;
       
       while (ring->req_cons != ring->req_prod) {
           uint32_t idx = ring->req_cons % RING_SIZE;
           struct vgpu_request *req = &ring->requests[idx];
           
           // Process command
           handle_command(vm, req);
           
           // Move to next request
           ring->req_cons++;
       }
   }

Step 5.6: Command Execution
   Task: Execute GPU operations based on command type
   
   File: mediator_cuda.c
   
   Function: handle_command(struct vm_context *vm, struct vgpu_request *req)
   
   Example for VECTOR_ADD:
   
   int execute_vector_add(struct vgpu_response *rsp) {
       const int N = 1024;
       float *h_a, *h_b, *h_c;  // Host arrays
       float *d_a, *d_b, *d_c;  // Device arrays
       
       // Allocate host memory
       h_a = (float*)malloc(N * sizeof(float));
       h_b = (float*)malloc(N * sizeof(float));
       h_c = (float*)malloc(N * sizeof(float));
       
       // Initialize data
       for (int i = 0; i < N; i++) {
           h_a[i] = i;
           h_b[i] = i * 2;
       }
       
       // Allocate device memory
       cudaMalloc(&d_a, N * sizeof(float));
       cudaMalloc(&d_b, N * sizeof(float));
       cudaMalloc(&d_c, N * sizeof(float));
       
       // Copy to device
       cudaMemcpy(d_a, h_a, N * sizeof(float), cudaMemcpyHostToDevice);
       cudaMemcpy(d_b, h_b, N * sizeof(float), cudaMemcpyHostToDevice);
       
       // Launch kernel
       vector_add_kernel<<<1, 256>>>(d_a, d_b, d_c, N);
       
       // Wait for completion
       cudaDeviceSynchronize();
       
       // Copy result back
       cudaMemcpy(h_c, d_c, N * sizeof(float), cudaMemcpyDeviceToHost);
       
       // Verify
       int errors = 0;
       for (int i = 0; i < N; i++) {
           if (h_c[i] != h_a[i] + h_b[i]) {
               errors++;
           }
       }
       
       // Clean up
       cudaFree(d_a);
       cudaFree(d_b);
       cudaFree(d_c);
       free(h_a);
       free(h_b);
       free(h_c);
       
       // Set response
       rsp->status = (errors == 0) ? 0 : -1;
       snprintf(rsp->data, sizeof(rsp->data), 
                "Vector add: %d elements, %d errors", N, errors);
       
       return rsp->status;
   }

Step 5.7: Response Handling
   Task: Write results back to VM
   
   Steps:
   1. Fill in vgpu_response structure
   2. Write to ring buffer response slot
   3. Update rsp_prod index
   4. Signal VM via event channel
   
   Function: send_response(struct vm_context *vm, struct vgpu_response *rsp)
   
   Example:
   
   void send_response(struct vm_context *vm, struct vgpu_response *rsp) {
       struct vgpu_ring *ring = vm->shared;
       
       // Get next response slot
       uint32_t idx = ring->rsp_prod % RING_SIZE;
       
       // Copy response
       memcpy(&ring->responses[idx], rsp, sizeof(*rsp));
       
       // Update producer index
       ring->rsp_prod++;
       
       // Signal VM
       notify_via_evtchn(vm->evtchn_fd);
   }

Step 5.8: Simple Scheduler (Phase 1)
   Task: For Phase 1, just process commands in order
   
   File: mediator_scheduler.c
   
   For Phase 1, no fancy scheduling needed:
   - Process commands first-come-first-served
   - One command at a time (no parallelism yet)
   - Just execute each command as it arrives
   
   Phase 2 will add:
   - Per-VM queues
   - Round-robin scheduling
   - Fair sharing

Step 5.9: Error Handling
   Task: Handle GPU errors gracefully
   
   Scenarios:
   - CUDA error during kernel launch
   - GPU timeout
   - Invalid command from VM
   - VM disappears mid-command
   
   Response:
   - Set error code in response
   - Log error
   - Continue processing other VMs
   - Don't crash the whole daemon

Step 5.10: Logging and Metrics
   Task: Add logging for debugging
   
   What to log:
   - VM connections/disconnections
   - Commands received and executed
   - Errors
   - Performance metrics (optional for Phase 1)
   
   Use: syslog() or simple file logging

Estimated Time for Mediation Daemon:
-------------------------------------
Senior Developer: 6-8 days
Breakdown:
  - Day 1-2: Basic daemon structure, CUDA initialization
  - Day 3-4: Xen shared memory and event channel integration
  - Day 5-6: Command processing and CUDA execution
  - Day 7: Error handling and logging
  - Day 8: Testing with real VM

================================================================================
SECTION 6: STEP-BY-STEP IMPLEMENTATION PLAN
================================================================================

Recommended Order:
------------------
Do NOT try to build everything at once!
Build incrementally and test each step.

PHASE 1A: Hello World (1 week)
-------------------------------

Step 1: Set Up Development Environment
   Time: 1 day
   Tasks:
   - Install XCP-ng test host
   - Create test VM (Ubuntu/CentOS)
   - Install CUDA toolkit on host
   - Install Xen development headers (libxl-dev, xenstore-dev)
   - Verify H100 is working with simple CUDA test on host
   
Step 2: Create Minimal Mediation Daemon (Host Only Test)
   Time: 2 days
   Tasks:
   - Write simple C program that runs vector_add on H100
   - Test CUDA works correctly
   - Add basic logging
   Goal: Prove you can run CUDA on host from user-space
   
Step 3: Test Xen Shared Memory (No VM Yet)
   Time: 2 days
   Tasks:
   - Write two programs: producer and consumer
   - Producer writes to shared memory
   - Consumer reads from shared memory
   - Use Xen grant tables API
   Goal: Understand Xen shared memory mechanism

PHASE 1B: VM-to-Host Communication (2 weeks)
---------------------------------------------

Step 4: Implement PCI Stub Device (Basic)
   Time: 5 days
   Tasks:
   - Create minimal Xen device backend
   - Present simple PCI device to VM
   - Device appears in lspci
   - Set up one BAR (4KB memory region)
   Goal: VM can see the device
   
Step 5: Implement Guest Driver (Basic)
   Time: 4 days
   Tasks:
   - Detect PCI device in VM
   - Create /dev/vgpu_stub
   - Handle simple write operations
   - Create test program that writes to /dev/vgpu_stub
   Goal: VM can open device and write to it
   
Step 6: Connect Guest to Host via Shared Memory
   Time: 3 days
   Tasks:
   - Set up ring buffer between VM and host
   - Guest writes command to ring
   - Host reads command from ring
   Goal: Data flows from VM to host

PHASE 1C: End-to-End GPU Execution (2 weeks)
---------------------------------------------

Step 7: Integrate Mediation Daemon with Shared Memory
   Time: 4 days
   Tasks:
   - Daemon monitors ring buffer
   - Reads commands from VM
   - Executes dummy response (no GPU yet)
   - Writes response back to VM
   Goal: Full round-trip communication VM → host → VM
   
Step 8: Add Real CUDA Execution
   Time: 3 days
   Tasks:
   - When daemon receives VECTOR_ADD command
   - Execute real CUDA kernel
   - Return actual result to VM
   Goal: VM command causes real GPU work
   
Step 9: Complete Test Application
   Time: 2 days
   Tasks:
   - Write VM test program
   - Opens /dev/vgpu_stub
   - Sends VECTOR_ADD command
   - Waits for response
   - Prints "Test passed!"
   Goal: Proof of concept working

Step 10: Two-VM Test
   Time: 3 days
   Tasks:
   - Create second VM
   - Both VMs run test simultaneously
   - Mediation daemon handles both
   - Both VMs get correct results
   Goal: Prove multi-VM sharing works

PHASE 1D: Polish and Documentation (1 week)
--------------------------------------------

Step 11: Error Handling
   Time: 2 days
   Tasks:
   - Add error checking everywhere
   - Handle VM crashes
   - Handle GPU errors
   - Graceful degradation
   
Step 12: Documentation
   Time: 3 days
   Tasks:
   - Write setup instructions
   - Document build process
   - Create test procedures
   - Write Phase 1 report

================================================================================
SECTION 7: TIME ESTIMATES SUMMARY
================================================================================

Component Time Breakdown (Senior Developer):
---------------------------------------------

1. PCI Stub Device:           5-7 days
2. VM Guest Driver:           4-6 days
3. Mediation Daemon:          6-8 days
4. Integration & Testing:     5-7 days
5. Two-VM Testing:            3-4 days
6. Documentation & Polish:    3-5 days
   ----------------------------------------
   TOTAL:                     26-37 days

Realistic Timeline:
-------------------

Best Case (everything works first try):  4-5 weeks
Realistic Case (normal debugging):       6-8 weeks
Worst Case (major issues):               10-12 weeks

Factors That Could Add Time:
----------------------------
- Unfamiliarity with Xen internals: +1-2 weeks
- CUDA issues on H100: +3-5 days
- PCI device model bugs: +1 week
- Shared memory issues: +1 week
- Integration problems: +1-2 weeks

If You're New to Xen:
---------------------
Add 2-3 weeks for learning:
- Week 1: Study Xen architecture, read documentation
- Week 2: Experiment with simple Xen drivers
- Week 3: Understand grant tables and event channels

Total for Junior/Mid Developer:
--------------------------------
Could be 12-16 weeks (3-4 months) for someone new to hypervisor development

================================================================================
SECTION 8: TESTING STRATEGY
================================================================================

Test Phase 1: Component Testing
--------------------------------

Test 1.1: Host CUDA Test
   Command: ./cuda_test
   Expected: "Vector add passed: 1024 elements"
   
Test 1.2: Shared Memory Test
   Host: ./shm_producer
   Host: ./shm_consumer
   Expected: Consumer receives data from producer
   
Test 1.3: PCI Device Detection
   VM: lspci
   Expected: See vGPU stub device (vendor 0x1AF4, device 0x1111)
   
Test 1.4: Guest Driver Load
   VM: insmod vgpu_guest.ko
   VM: ls /dev/vgpu_stub
   Expected: Device file exists
   
Test 1.5: Basic Write Test
   VM: echo "TEST" > /dev/vgpu_stub
   Host: Check daemon log
   Expected: Daemon receives "TEST"

Test Phase 2: Integration Testing
----------------------------------

Test 2.1: NOP Command
   VM: ./gpu_test nop
   Expected: "NOP command successful"
   Purpose: Test basic round-trip
   
Test 2.2: Vector Add
   VM: ./gpu_test vector_add
   Expected: "Vector add passed: 1024 elements, 0 errors"
   Purpose: Test real GPU execution
   
Test 2.3: Multiple Commands
   VM: for i in {1..10}; do ./gpu_test vector_add; done
   Expected: All 10 commands succeed
   Purpose: Test repeated execution
   
Test 2.4: Error Handling
   VM: ./gpu_test invalid_command
   Expected: "Error: Invalid command"
   Purpose: Test error handling

Test Phase 3: Multi-VM Testing
-------------------------------

Test 3.1: Two VMs Sequential
   VM1: ./gpu_test vector_add
   Wait for completion
   VM2: ./gpu_test vector_add
   Expected: Both succeed
   
Test 3.2: Two VMs Concurrent
   VM1: ./gpu_test vector_add &
   VM2: ./gpu_test vector_add &
   Expected: Both succeed, neither crashes
   Purpose: MAIN PHASE 1 GOAL
   
Test 3.3: Stress Test
   VM1: while true; do ./gpu_test vector_add; done &
   VM2: while true; do ./gpu_test vector_add; done &
   Run for 10 minutes
   Expected: No crashes, both keep working

================================================================================
SECTION 9: TROUBLESHOOTING GUIDE
================================================================================

Problem 1: VM doesn't see PCI device
-------------------------------------
Check:
- xl dmesg (Xen hypervisor log)
- Is device backend loaded?
- Check XenStore: xenstore-ls /local/domain/0/backend/vgpu
- VM kernel config: CONFIG_PCI enabled?

Problem 2: Guest driver can't load
-----------------------------------
Check:
- dmesg in VM
- Is PCI vendor/device ID correct in driver?
- Kernel version compatibility
- Missing kernel config options

Problem 3: Shared memory not working
-------------------------------------
Check:
- Grant table permissions
- Is grant reference correct?
- Use xenstore-read to verify grant ref
- Check host can map guest memory

Problem 4: Event channel not firing
------------------------------------
Check:
- Event channel binding correct?
- Port number matches?
- Is interrupt enabled in VM?
- Use evtchn_status to debug

Problem 5: CUDA fails on host
------------------------------
Check:
- nvidia-smi shows H100?
- CUDA version compatible?
- Run simple CUDA sample
- Check /dev/nvidia0 permissions

Problem 6: Commands not reaching daemon
----------------------------------------
Check:
- Is daemon running? (ps aux | grep mediator)
- Daemon logs show anything?
- Ring buffer indices (print req_prod, req_cons)
- Is shared memory actually shared?

Problem 7: VM gets wrong results
---------------------------------
Check:
- Response ID matches request ID?
- Ring buffer not overflowing?
- Race condition in ring updates?
- Print all ring indices

Problem 8: Two VMs cause crash
-------------------------------
Check:
- Memory corruption (use valgrind on daemon)
- Context isolation (each VM separate ring?)
- CUDA stream usage (one per VM?)
- GPU reset (nvidia-smi -r)

================================================================================
SECTION 10: ADDITIONAL NOTES
================================================================================

Important Considerations:
-------------------------

1. Start Simple
   Don't try to build everything perfectly
   Get basic communication working first
   Add features incrementally

2. Log Everything
   Add printf/logging at every step
   You'll spend 50% of time debugging
   Logs are your best friend

3. Use Existing Examples
   Look at other Xen device models (blkback, netback)
   Copy patterns that work
   Don't reinvent the wheel

4. Test on Every Change
   After each code change, test immediately
   Don't write 1000 lines then test
   Small changes = easier debugging

5. Version Control
   Use git
   Commit after each working step
   You'll need to rollback sometimes

6. Ask for Help
   Xen mailing lists are helpful
   NVIDIA developer forums for CUDA
   Stack Overflow for Linux kernel

Required Reading:
-----------------

1. Xen Documentation
   - Xen Wiki: wiki.xen.org
   - "The Definitive Guide to the Xen Hypervisor"
   
2. Linux Device Drivers
   - "Linux Device Drivers, 3rd Edition" (free online)
   - Focus on Chapter 3 (char drivers) and Chapter 12 (PCI)

3. CUDA Programming
   - NVIDIA CUDA C Programming Guide
   - Focus on basic kernel launch, memory management

4. Grant Tables and Event Channels
   - Xen Grant Tables Documentation
   - Xen Event Channels Documentation

Tools You'll Need:
------------------

Host:
- gcc, make
- Xen development packages (libxl-dev, libxenstore3.0-dev)
- CUDA toolkit (nvcc, CUDA runtime)
- gdb for debugging

VM:
- Linux kernel headers
- gcc, make
- gdb

Debugging:
- xl dmesg (Xen hypervisor messages)
- dmesg (Linux kernel messages)
- xenstore-ls (examine XenStore)
- nvidia-smi (GPU status)
- strace (trace system calls)
- gdb (debugger)

================================================================================
END OF IMPLEMENTATION GUIDE
================================================================================

Next Steps:
1. Read this document carefully
2. Set up your development environment
3. Start with Phase 1A (Hello World)
4. Ask questions when stuck
5. Take it one step at a time

Remember: Phase 1 is a proof-of-concept. It doesn't need to be perfect.
The goal is to prove that VM → Host → GPU → VM works!

Good luck!
